{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94b8d8-6825-46ce-9af8-69c068b51e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10, sqrt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim_frame\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cpbd\n",
    "from deepface import DeepFace as DF\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "def check(true, pred):\n",
    "    # check for format, it needs to be imageio.plugins.ffmpeg.FfmpegFormat.Reader\"\n",
    "    assert type(true) == imageio.plugins.ffmpeg.FfmpegFormat.Reader\n",
    "    \n",
    "    # check for frame counts, they need to be equal\n",
    "    l1 = true.count_frames()\n",
    "    l2 = pred.count_frames()\n",
    "    print(l1)\n",
    "    print(l2)\n",
    "    #assert l1 == l2 # \"Different frame numbers!\"\n",
    "    \n",
    "    # check for different image resolutions\n",
    "    assert np.array(true.get_data(0)).shape == np.array(pred.get_data(0)).shape\n",
    "    \n",
    "def check_v2(pred):\n",
    "    # check for format, it needs to be imageio.plugins.ffmpeg.FfmpegFormat.Reader\"\n",
    "    assert type(pred) == imageio.plugins.ffmpeg.FfmpegFormat.Reader\n",
    "    \n",
    "def to_grayscale(im):\n",
    "    return np.array(im[:, :, 0] * 0.2989 + im[:, :, 1] * 0.5870 + im[:, :, 2] * 0.1140)\n",
    "\n",
    "# metric 1: PSNR, Peak Signal to Noise Ratio\n",
    "# range: usuall 25-50dB, higher the score, better the prediction\n",
    "def eval_psnr(true, pred, offset = 0):\n",
    "    #check(true, pred)\n",
    "    def psnr_frame(true, pred):\n",
    "        mse = np.mean((true - pred) ** 2)\n",
    "        if (mse == 0):\n",
    "            return 100\n",
    "        return 20 * log10(np.max(true) / sqrt(mse))\n",
    "    \n",
    "    psnrs = []\n",
    "    l1 = true.count_frames()\n",
    "    for i in range(30):\n",
    "        psnrs.append(psnr_frame(true.get_data(i), pred.get_data(i)))\n",
    "    return sum(psnrs) / 30\n",
    "\n",
    "# metric 2: SSIM, Structural Similarity Index\n",
    "# range: 0-1, higher the score, similar the images\n",
    "def eval_ssim(true, pred, offset = 0):\n",
    "    #check(true, pred)\n",
    "    \n",
    "    ssims = []\n",
    "    l1 = true.count_frames()\n",
    "    for i in range(30):\n",
    "        ssims.append(ssim_frame(true.get_data(i), pred.get_data(i), channel_axis=2))\n",
    "    return sum(ssims) / 30\n",
    "\n",
    "# metric 3: CPBD, Cumulative Probability Blur Detection\n",
    "# range: 0-1, higher the score, sharper (less blur) the image\n",
    "def eval_cpbd(pred):\n",
    "    check_v2(pred)\n",
    "    \n",
    "    cpbds = []\n",
    "    l1 = pred.count_frames()\n",
    "    for i in range(l1):\n",
    "        cpbds.append(cpbd.compute(to_grayscale(pred.get_data(i))))\n",
    "    return sum(cpbds) / l1\n",
    "\n",
    "# metric 4.1: ACD-I, Average Content Distance-Identity\n",
    "def eval_acdi(pred):\n",
    "    check_v2(pred)\n",
    "    \n",
    "    acdis = []\n",
    "    l1 = pred.count_frames()\n",
    "    prev_grayscale = to_grayscale(pred.get_data(0))\n",
    "    for i in range(1, l1):\n",
    "        current_grayscale = to_grayscale(pred.get_data(i))\n",
    "        acdis.append( np.mean((current_grayscale - prev_grayscale)**2) )\n",
    "        prev_grayscale = current_grayscale\n",
    "    return sum(acdis) / (l1 - 1)\n",
    "\n",
    "# metric 4.2: ACD-C, Average Content Distance-Context\n",
    "def eval_acdc(pred):\n",
    "    check_v2(pred)\n",
    "    filename = \"im3.jpg\"\n",
    "    \n",
    "    acdcs = []\n",
    "    l1 = pred.count_frames()\n",
    "    Image.fromarray(pred.get_data(0)).save(filename)\n",
    "    prev_rep = np.array(DF.represent(filename, enforce_detection = False, model_name = \"OpenFace\"))\n",
    "    for i in range(1, l1):\n",
    "        Image.fromarray(pred.get_data(i)).save(filename)\n",
    "        current_rep = DF.represent(filename, enforce_detection = False, model_name = \"OpenFace\")\n",
    "        acdcs.append( np.mean((np.array(current_rep[0]['embedding']) - np.array(prev_rep[0]['embedding']))**2) )\n",
    "        prev_rep = current_rep\n",
    "    return sum(acdcs) / (l1 - 1)\n",
    "\n",
    "# metric 5: Blinks/sec, Blink duration based on EAR (eye aspect ratio)\n",
    "FACIAL_LANDMARK_PREDICTOR = \"shape_predictor_68_face_landmarks.dat\"\n",
    "EAR_TH_FOR_BLINK = 0.1\n",
    "\n",
    "faceDetector = dlib.get_frontal_face_detector()\n",
    "landmarkFinder = dlib.shape_predictor(FACIAL_LANDMARK_PREDICTOR)\n",
    "\n",
    "(leftEyeStart, leftEyeEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rightEyeStart, rightEyeEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "def eye_aspect_ratio(eye):\n",
    "    p2_minus_p6 = dist.euclidean(eye[1], eye[5])\n",
    "    p3_minus_p5 = dist.euclidean(eye[2], eye[4])\n",
    "    p1_minus_p4 = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (p2_minus_p6 + p3_minus_p5) / (2.0 * p1_minus_p4)\n",
    "    return ear\n",
    "def eval_ear(testVid):\n",
    "    last_open_frame_idx = 0\n",
    "    blink_ct = 0\n",
    "    closed = False\n",
    "\n",
    "    durations = []\n",
    "    #try:\n",
    "    \n",
    "    \n",
    "    for i in range(int(testVid.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        (status, image) = testVid.read()\n",
    "        image = imutils.resize(image, width=800)\n",
    "        grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceDetector(grayImage, 0)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            ear = 0.35\n",
    "        else:\n",
    "            faceLandmarks = landmarkFinder(grayImage, faces[0])\n",
    "            faceLandmarks = face_utils.shape_to_np(faceLandmarks)\n",
    "            leftEye = faceLandmarks[leftEyeStart:leftEyeEnd]\n",
    "            rightEye = faceLandmarks[rightEyeStart:rightEyeEnd]\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "        if ear < 0.2:\n",
    "            if not closed:\n",
    "                blink_ct += 1\n",
    "                closed = True\n",
    "                #print(\"BLINK\")\n",
    "        elif ear > 0.25:\n",
    "            if closed:\n",
    "                closed = False\n",
    "                durations.append((i - last_open_frame_idx) / int(testVid.get(cv2.CAP_PROP_FRAME_COUNT)) *1.22)\n",
    "            last_open_frame_idx = i\n",
    "    if len(durations) == 0:\n",
    "        return (0, np.nan)\n",
    "        durations = [0]\n",
    "    #print(blink_ct, durations)\n",
    "    #print(blink_ct / 1.22, sum(durations)/len(durations))\n",
    "    return blink_ct / 1.22, sum(durations)/len(durations)\n",
    "\n",
    "\n",
    "    #except:\n",
    "        #0.39 blinks/sec, 0.41sec / blink\n",
    "        #print(blink_ct / 1.22, sum(durations)/len(durations))\n",
    "        #return 0.39, 0.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d0522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78fffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = \"results_comparison_resized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36717755-57c0-4d76-99fc-c575e0d9c625",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in [3,5,7,9,10,11,12,14]:\n",
    "    model_path = f\"results_exp{i}/\"\n",
    "    import os, time\n",
    "    original_files = os.listdir(original_path)\n",
    "    model_files = os.listdir(model_path)\n",
    "    print(len(model_files),len(original_files))\n",
    "\n",
    "    s = time.time()\n",
    "    model_evals = {}\n",
    "    count = 0\n",
    "    psnr_sum = 0\n",
    "    ssim_sum = 0\n",
    "    cpbd_sum = 0\n",
    "    acdi_sum = 0\n",
    "    acdc_sum = 0\n",
    "    ear_sum1 = 0\n",
    "    ear_sum2 = 0\n",
    "    count2 = 0\n",
    "    for video_name in original_files:\n",
    "        try:\n",
    "            orig_vid = imageio.get_reader(original_path + \"/\" + video_name, 'ffmpeg')\n",
    "            #model_vid = imageio.get_reader(model_path + \"/\" + video_name, 'ffmpeg')\n",
    "            model_vid = cv2.VideoCapture(model_path + \"/\" + video_name)\n",
    "        except:\n",
    "            print(f\"missing either {sda_video_name} or {mit_video_name} or {sda_resized_video_name} skipping!\")\n",
    "            missing_files.append(video_name)\n",
    "            continue\n",
    "        count+=1\n",
    "        \"\"\"\n",
    "        # 1. eval psnr\n",
    "        psnr_model = eval_psnr(orig_vid, model_vid, offset=1)\n",
    "        psnr_sum += psnr_model\n",
    "        # 2. eval ssim\n",
    "        ssim_model = eval_ssim(orig_vid, model_vid, offset=1)\n",
    "        ssim_sum += ssim_model\n",
    "        # 3. eval cpbd\n",
    "        cpbd_model = eval_cpbd(model_vid)\n",
    "        cpbd_sum += cpbd_model\n",
    "        # 4.1. eval acdi\n",
    "        acdi_model = eval_acdi(model_vid)\n",
    "        acdi_sum += acdi_model\n",
    "        # 4.2. eval acdc\n",
    "        acdc_model = eval_acdc(model_vid)\n",
    "        acdc_sum += acdc_model\n",
    "        \"\"\"\n",
    "        ear_model = eval_ear(model_vid)\n",
    "        ear_sum1 += ear_model[0]\n",
    "        if(ear_model[1] != np.nan):\n",
    "            print(ear_model[1])\n",
    "            count2+=1\n",
    "            ear_sum2 += ear_model[1]\n",
    "    #print(f\"Experiment {i} PSNR: {psnr_sum/count} SSIM: {ssim_sum/count} CPBD: {cpbd_sum/count} ACDI: {acdi_sum/count} ACDC: {acdc_sum/count}\")\n",
    "    print(f\"Experiment {i} EAR: {ear_sum1/count} {ear_sum2/count2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ea4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "64 64\n",
    "Experiment 1 EAR: 0.0 nan\n",
    "64 64\n",
    "Experiment 2 EAR: 0.0 nan\n",
    "64 64\n",
    "Experiment 3 EAR: 0.10245901639344264 nan\n",
    "64 64\n",
    "Experiment 4 EAR: 0.0 nan\n",
    "64 64\n",
    "Experiment 5 EAR: 0.07684426229508198 nan\n",
    "64 64\n",
    "Experiment 6 EAR: 0.0 nan\n",
    "64 64\n",
    "Experiment 7 EAR: 0.025614754098360656 nan\n",
    "64 64\n",
    "Experiment 8 EAR: 0.0 nan\n",
    "64 64\n",
    "Experiment 9 EAR: 0.012807377049180328 nan\n",
    "64 64\n",
    "Experiment 10 EAR: 0.025614754098360656 nan\n",
    "64 64\n",
    "Experiment 11 EAR: 0.012807377049180328 nan\n",
    "64 64\n",
    "Experiment 12 EAR: 0.025614754098360656 nan\n",
    "64 64\n",
    "Experiment 13 EAR: 0.0 nan\n",
    "64 64\n",
    "Experiment 14 EAR: 0.025614754098360656 nan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
